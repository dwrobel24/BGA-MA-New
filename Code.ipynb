{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09f54173",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "# This is the code I will be building for my thesis project that I am writing at the chair of Public Economics of Prof. Daniel Schunk\n",
    "# with Dr. Katharina Hartinger as my adviser.\n",
    "\n",
    "I will be documenting everything using these markdown cells to describe ideas, processes and problems that arise while writing the code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a89e151",
   "metadata": {},
   "source": [
    "# This is the code I will be building for my thesis project that I am writing at the chair of Public Economics of Prof. Daniel Schunk\n",
    "# with Dr. Katharina Hartinger as my adviser.\n",
    "\n",
    "I will be documenting everything using these markdown cells to describe ideas, processes and problems that arise while writing the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35f8db1",
   "metadata": {},
   "source": [
    "All the packages that will be imported to run the code for my thesis will be readable in the cell below. I have declared a variety of dataframes and csv to keep track of every change I have made to the original dataset, allowing me to closely check whether the algorithm worked as intended. Users who are experienced with the dataset can of course drop/ignore these dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8199ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import enchant\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1311dbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table Number</th>\n",
       "      <th>Move</th>\n",
       "      <th>Clues</th>\n",
       "      <th>Mystery Word</th>\n",
       "      <th>Guess</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Language</th>\n",
       "      <th>End</th>\n",
       "      <th>Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>312175859</td>\n",
       "      <td>1609</td>\n",
       "      <td>Koperta, Naklejony, Pocztowy, Pocztówka</td>\n",
       "      <td>Stamp</td>\n",
       "      <td>Znaczek</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>312175859</td>\n",
       "      <td>1615</td>\n",
       "      <td>W, Rimmikub, Glazura, Kwadracik</td>\n",
       "      <td>Tile</td>\n",
       "      <td>Płytka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>312175859</td>\n",
       "      <td>1626</td>\n",
       "      <td>Grajek, Baśń, Ta, Tuj</td>\n",
       "      <td>Rat</td>\n",
       "      <td>Bard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>312175859</td>\n",
       "      <td>1632</td>\n",
       "      <td>Płacony, Restauracja, Kid, Western</td>\n",
       "      <td>Bill</td>\n",
       "      <td>Tip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312175859</td>\n",
       "      <td>1638</td>\n",
       "      <td>Władzy, Złoty, Tytanowy, Obrączka</td>\n",
       "      <td>Ring</td>\n",
       "      <td>Ring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Table Number  Move                                    Clues Mystery Word  \\\n",
       "0     312175859  1609  Koperta, Naklejony, Pocztowy, Pocztówka        Stamp   \n",
       "1     312175859  1615          W, Rimmikub, Glazura, Kwadracik         Tile   \n",
       "2     312175859  1626                    Grajek, Baśń, Ta, Tuj          Rat   \n",
       "3     312175859  1632       Płacony, Restauracja, Kid, Western         Bill   \n",
       "4     312175859  1638        Władzy, Złoty, Tytanowy, Obrączka         Ring   \n",
       "\n",
       "     Guess Mode Speed Language  End  Success  \n",
       "0  Znaczek  NaN   NaN      NaN  NaN        0  \n",
       "1   Płytka  NaN   NaN      NaN  NaN        0  \n",
       "2     Bard  NaN   NaN      NaN  NaN        0  \n",
       "3      Tip  NaN   NaN      NaN  NaN        0  \n",
       "4     Ring  NaN   NaN      NaN  NaN        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Game_data_05_08_24.csv\")  \n",
    "\n",
    "# Create the 'Success' column\n",
    "df['Success'] = df.apply(lambda row: 1 if row['Guess'] == row['Mystery Word'] else 0, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9995de",
   "metadata": {},
   "source": [
    "Hier schreibe ich alles auf, was ich an dem Datensatz irgendwie verändere bzw. welche Probleme ich versuche zu lösen:\n",
    "\n",
    "1. Das Sprachenproblem: ganz viele Runden haben leider keine Klassifizierung, in welcher Sprache sie gespielt wurden. Das ist insofern problematisch, da ich ja auch die Sprache als potenziellen Prädiktor nutzen möchte. Daher möchte ich für alle Runden die Sprache kennen. Wie finde ich also heraus, in welcher Sprache gespielt wurde?\n",
    "\n",
    "**Lösungsansatz:**\n",
    "Ich lasse Wörterbücher über Mystery Word, Guess und Clues laufen, um zunächst alle Sprachen zu erkennen. Dann vergleiche ich die erkannten Sprachen- wenn diese übereinstimmen, wird die Rundensprache auf das entsprechende Match festgelegt. Ein Beispiel: das Mystery Word ist 'Bathroom', der Guess 'Toilet' und die Clues sind 'Morning', 'Shower', 'Sink' und 'Towel'. Hierbei sollte der Algorithmus jetzt feststellen, dass alle Wörter in der englischen Sprache existieren und somit die Rundensprache auf Englisch setzen. \n",
    "\n",
    "**Probleme:** \n",
    "1. Die Wörterbücher erkennen viele Dinge nicht bzw. falsch. Gerade polnische Wörter sind für den Algorithmus schwierig. \n",
    "2. Die Wörter existieren in mehreren Sprachen. Z.B. das Wort 'Bad' existiert sowohl im Deutschen als auch im Englischen. Der Algorithmus erkennt hier insofern ein Match sowohl im deutschen als auch im englichen Wörterbuch. Das kann natürlich zu Problemen führen. Daher vergleicht der Algorithmus jeweils immer unabhängig- es ist nicht schlimm, wenn ein Wort in mehreren Sprachen existiert, solang eine der Sprachen über alle Kategorien matcht. \n",
    "3. \n",
    "\n",
    "2. Das Sprachenproblem, fortgesetzt: für spätere Analysen, besonders im Rahmen des Originalitätsmaßes, ist es wichtig, dass alle Wörter in der gleichen Sprache, also der Rundensprache sind. Denn logischerweise wäre ein Wort in französischer Sprache sehr weit entfernt von einem in der deutschen Sprache- selbst wenn die Bedeutung gar nicht so weit voneinander entfernt ist. Daher müssen tatsächlich alle Wörter, die nicht in der Rundensprache existieren, aussortiert werden- und ihre Runden der Konsistenz halber gleich mit. Um das zu erreichen, werde ich eine zweite Runde an Checks einbauen, die, sobald eine Sprache festgelegt wurde, die Clues erneut überprüft, und im Fall, dass ein Wort nicht im Wörterbuch dieser Sprache existiert, die Runde entfernt. \n",
    "\n",
    "Hierbei muss ich aber noch schauen, wieviele Datenpunkte mir hinterher übrig bleiben. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c762ee3",
   "metadata": {},
   "source": [
    "## Documentation for Removing Rounds with NaN Values and Storing Them Separately\n",
    "\n",
    "### Overview\n",
    "This script is designed to clean a dataset by identifying and removing rounds (rows) that contain missing values (`NaN`) in key columns. The removed rounds are stored in a separate dataset for potential future analysis or review. The script also provides a summary of how many rounds were retained and how many were removed.\n",
    "\n",
    "### Purpose\n",
    "The cleaning process focuses on four key columns:\n",
    "1. `Mode`\n",
    "2. `Speed`\n",
    "3. `Language`\n",
    "4. `End`\n",
    "\n",
    "Rounds with missing values in any of these columns are considered incomplete and are removed from the main dataset. The removed rounds are stored in a separate dataset, allowing for a clear distinction between complete and incomplete data.\n",
    "\n",
    "### Code Breakdown\n",
    "\n",
    "1. **Loading the Dataset**:\n",
    "   - The dataset is loaded into a pandas DataFrame for processing.\n",
    "\n",
    "2. **Identifying and Separating Incomplete Rounds**:\n",
    "   - The script checks for missing (`NaN`) values in the specified columns (`Mode`, `Speed`, `Language`, `End`).\n",
    "   - Rounds with any `NaN` values in these columns are separated into a new DataFrame (`removed_rounds`).\n",
    "   - The remaining rounds, which are complete, are stored in another DataFrame (`cleaned_data`).\n",
    "\n",
    "3. **Counting the Rounds**:\n",
    "   - The script calculates and prints the number of rounds that were retained (i.e., those without `NaN` values).\n",
    "   - It also calculates and prints the number of rounds that were removed due to missing values.\n",
    "\n",
    "4. **Output**:\n",
    "   - The cleaned dataset is ready for further analysis, while the removed rounds are preserved for any necessary follow-up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14035, 8373)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate the rounds with NaN values in 'Mode', 'Speed', 'Language', or 'End' columns\n",
    "removed_rounds = df[df[['Mode', 'Speed', 'Language', 'End']].isna().any(axis=1)]\n",
    "cleaned_data = df.dropna(subset=['Mode', 'Speed', 'Language', 'End'])\n",
    "\n",
    "# Count the number of rounds\n",
    "total_rounds = df.shape[0]\n",
    "cleaned_rounds_count = cleaned_data.shape[0]\n",
    "removed_rounds_count = removed_rounds.shape[0]\n",
    "\n",
    "# Print the counts\n",
    "cleaned_rounds_count, removed_rounds_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation: Removing Rounds Based on Clue Content\n",
    "\n",
    "## Overview\n",
    "This script is designed to clean a dataset by identifying and removing entire rounds (rows) of data where any clue contains special characters, numbers, or multiple words (indicated by spaces). The script also saves the removed rounds to a separate CSV file for further analysis or review.\n",
    "\n",
    "## Purpose\n",
    "The goal of this script is to ensure the integrity of your dataset by removing any rounds that could skew the analysis. Specifically, it addresses the following issues:\n",
    "1. **Special Characters**: Any clue containing characters other than letters, numbers, underscores, or spaces is flagged.\n",
    "2. **Numbers**: Clues containing numeric digits are flagged.\n",
    "3. **Multiple Words**: Clues containing more than one word (indicated by spaces) are flagged.\n",
    "\n",
    "If any clue in a round meets any of these criteria, the entire round is removed from the dataset.\n",
    "\n",
    "## Code Breakdown\n",
    "\n",
    "### 1. **Copying the Dataset**\n",
    "   - `df_cleaned = cleaned_data.copy()`\n",
    "   - This creates a copy of the original dataset to avoid modifying it directly. All cleaning operations are performed on this copy.\n",
    "\n",
    "### 2. **Initialization**\n",
    "   - The script initializes dictionaries to store the counts and lists of removed words based on the specific reason for their removal:\n",
    "     - `special_characters`\n",
    "     - `numbers`\n",
    "     - `spaces`\n",
    "\n",
    "### 3. **Defining the `clean_rounds` Function**\n",
    "   - This function iterates over each row in the dataset and checks each clue in the 'Clues' column:\n",
    "     - **Special Characters**: Uses the regular expression `r'[^\\w\\s]'` to identify and flag any special characters.\n",
    "     - **Numbers**: Uses `r'\\d'` to detect any numeric digits in the clues.\n",
    "     - **Spaces**: Checks for spaces to determine if the clue consists of multiple words.\n",
    "   - If any clue in a round meets the criteria, the round is marked for deletion.\n",
    "   - The removed rounds are saved to a separate DataFrame.\n",
    "\n",
    "### 4. **Applying the `clean_rounds` Function**\n",
    "   - `df_cleaned, removed_rounds = clean_rounds(df_cleaned, 'Clues')`\n",
    "   - The function is applied to the dataset, cleaning it by removing the identified rounds and storing those rounds separately.\n",
    "\n",
    "### 5. **Saving the Results**\n",
    "   - The cleaned dataset and the removed rounds are saved to separate CSV files:\n",
    "     - `'cleaned_data_with_cleaned_clues.csv'` for the cleaned data.\n",
    "     - `'removed_rounds.csv'` for the rounds that were removed.\n",
    "\n",
    "### 6. **Summary Output**\n",
    "   - The script prints a summary of the number of words (or clues) that were flagged and removed for each category (`special_characters`, `numbers`, `spaces`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff387bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Removed Words:\n",
      " - Special Characters: 1100\n",
      " - Numbers: 319\n",
      " - Spaces (multiple words): 0\n",
      " - Total Removed Words: 1419\n",
      "\n",
      "Files have been saved:\n",
      " - Cleaned data with cleaned clues: 'cleaned_data_with_cleaned_clues.csv'\n",
      " - Removed rounds: 'removed_rounds.csv'\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the dataset to avoid modifying the original data\n",
    "df_cleaned = cleaned_data.copy()\n",
    "\n",
    "# Initialize dictionaries to store removed words counts and lists\n",
    "removed_words_counts = {\n",
    "    'special_characters': 0,\n",
    "    'numbers': 0,\n",
    "    'spaces': 0\n",
    "}\n",
    "\n",
    "removed_words_lists = {\n",
    "    'special_characters': [],\n",
    "    'numbers': [],\n",
    "    'spaces': []\n",
    "}\n",
    "\n",
    "# Function to clean entire rounds if any clue contains undesired characters\n",
    "def clean_rounds(dataframe, column_name):\n",
    "    rows_to_drop = []\n",
    "    for index, clues_string in dataframe[column_name].items():\n",
    "        clues_list = str(clues_string).split(',')\n",
    "        for clue in clues_list:\n",
    "            original_clue = clue.strip()\n",
    "            \n",
    "            # Check for special characters\n",
    "            if re.search(r'[^\\w\\s]', original_clue):\n",
    "                removed_words_lists['special_characters'].append(original_clue)\n",
    "                removed_words_counts['special_characters'] += 1\n",
    "                rows_to_drop.append(index)\n",
    "                break  # Skip further checks and mark the round for deletion\n",
    "            \n",
    "            # Check for numbers\n",
    "            if re.search(r'\\d', original_clue):\n",
    "                removed_words_lists['numbers'].append(original_clue)\n",
    "                removed_words_counts['numbers'] += 1\n",
    "                rows_to_drop.append(index)\n",
    "                break  # Skip further checks and mark the round for deletion\n",
    "            \n",
    "            # Check for spaces (multiple words)\n",
    "            if ' ' in original_clue:\n",
    "                removed_words_lists['spaces'].append(original_clue)\n",
    "                removed_words_counts['spaces'] += 1\n",
    "                rows_to_drop.append(index)\n",
    "                break  # Skip further checks and mark the round for deletion\n",
    "\n",
    "    # Save the removed rounds to a separate DataFrame\n",
    "    removed_rounds = dataframe.loc[rows_to_drop]\n",
    "    \n",
    "    # Drop the identified rows from the original DataFrame\n",
    "    dataframe = dataframe.drop(rows_to_drop)\n",
    "\n",
    "    return dataframe, removed_rounds\n",
    "\n",
    "# Apply the function to delete rounds instead of just words\n",
    "df_cleaned, removed_rounds = clean_rounds(df_cleaned, 'Clues')\n",
    "\n",
    "# Save the cleaned DataFrame and removed rounds DataFrame to CSV files\n",
    "df_cleaned.to_csv('cleaned_data_with_cleaned_clues.csv', index=False)\n",
    "removed_rounds.to_csv('removed_rounds.csv', index=False)\n",
    "\n",
    "# Print out the counts of removed words for each category\n",
    "print(\"Summary of Removed Words:\")\n",
    "print(f\" - Special Characters: {removed_words_counts['special_characters']}\")\n",
    "print(f\" - Numbers: {removed_words_counts['numbers']}\")\n",
    "print(f\" - Spaces (multiple words): {removed_words_counts['spaces']}\")\n",
    "print(f\" - Total Removed Words: {sum(removed_words_counts.values())}\")\n",
    "\n",
    "print(\"\\nFiles have been saved:\")\n",
    "print(\" - Cleaned data with cleaned clues: 'cleaned_data_with_cleaned_clues.csv'\")\n",
    "print(\" - Removed rounds: 'removed_rounds.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6125045c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of individual clues with quotation marks in the cleaned dataset: 0\n",
      "Number of individual clues with quotation marks in the cleaned dataset: 0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eeac0b29",
   "metadata": {},
   "source": [
    "# Documentation: Dictionary Validation and Clue Processing\n",
    "\n",
    "## Overview\n",
    "This script processes a dataset containing clues in multiple languages, validating each clue against language-specific dictionaries. It categorizes rounds based on the percentage of clues that are valid according to the dictionary and saves the results in different CSV files. The script also counts and prints the number of rows for each language, specifically focusing on French in this case.\n",
    "\n",
    "## Purpose\n",
    "The goal of this script is to clean and validate a dataset of clues by ensuring that they exist in the appropriate language dictionary. The script categorizes the rounds based on the percentage of valid clues and generates corresponding CSV files for further analysis.\n",
    "\n",
    "## Code Breakdown\n",
    "\n",
    "### 1. **Loading Dictionaries**\n",
    "   - The function `load_dictionary(file_name)` loads a dictionary file and converts the list of words into a lowercase set for efficient lookup.\n",
    "   - Dictionaries for English (`words.txt`), German (`vocab_german.txt`), and French (`francais.txt`) are loaded. The French dictionary came from this Git: https://github.com/Taknok/French-Wordlist/blob/master/francais.txt\n",
    "\n",
    "### 2. **Loading the Cleaned Dataset**\n",
    "   - The dataset is loaded from a CSV file named `cleaned_data_with_cleaned_clues.csv` into the DataFrame `df_cleaned_with_cleaned_clues`.\n",
    "\n",
    "### 3. **Validating Clues Against Dictionaries**\n",
    "   - The function `check_clues_against_dictionary(dataframe, clues_column, language_column)` iterates through each round in the dataset and validates clues against the appropriate dictionary based on the language of the round.\n",
    "   - **Categorization**:\n",
    "     - **Fully Valid Rounds**: Rounds where all clues are valid.\n",
    "     - **At Least 75% Valid Rounds**: Rounds where at least 75% of the clues are valid.\n",
    "     - **At Least 50% Valid Rounds**: Rounds where at least 50% of the clues are valid.\n",
    "     - **Invalid Rounds**: Rounds where fewer than 50% of the clues are valid.\n",
    "   - The function returns four DataFrames corresponding to these categories.\n",
    "\n",
    "### 5. **Saving the Results**\n",
    "   - The categorized DataFrames are saved as separate CSV files:\n",
    "     - `fully_valid_clues.csv`: Contains only rounds where every clue is valid.\n",
    "     - `atleast_75_valid_clues.csv`: Contains rounds where at least 75% of clues are valid.\n",
    "     - `atleast_50_valid_clues.csv`: Contains rounds where at least 50% of clues are valid.\n",
    "     - `invalid_rounds_due_to_dictionary.csv`: Contains rounds where fewer than 50% of the clues are valid.\n",
    "\n",
    "### 6. **Printing the Summary**\n",
    "   - The script prints a summary of the number of rounds in each category:\n",
    "     - **Rounds where every clue is valid**: Count of fully valid rounds.\n",
    "     - **Rounds where at least 75% of clues are valid**: Count of rounds with at least 75% valid clues.\n",
    "     - **Rounds where at least 50% of clues are valid**: Count of rounds with at least 50% valid clues.\n",
    "     - **Rounds rejected due to invalid clues**: Count of rounds with fewer than 50% valid clues.\n",
    "   - The total number of rows in the dataset is also printed.\n",
    "\n",
    "### 7. **Output Files**\n",
    "   - **`fully_valid_clues.csv`**: Rounds where all clues are valid.\n",
    "   - **`atleast_75_valid_clues.csv`**: Rounds with at least 75% valid clues.\n",
    "   - **`atleast_50_valid_clues.csv`**: Rounds with at least 50% valid clues.\n",
    "   - **`invalid_rounds_due_to_dictionary.csv`**: Rounds with less than 50% valid clues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91c38dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with 'French' as the language: 2941\n",
      "Summary of Rounds Based on Dictionary Validation:\n",
      " - Rounds where every clue is valid: 4965\n",
      " - Rounds where at least 75% of clues are valid: 8246\n",
      " - Rounds where at least 50% of clues are valid: 11050\n",
      " - Rounds rejected due to invalid clues: 1566\n",
      "Total number of rows in the dataset: 12616\n",
      "\n",
      "Files have been saved:\n",
      " - Fully valid clues: 'fully_valid_clues.csv'\n",
      " - At least 75% valid clues: 'atleast_75_valid_clues.csv'\n",
      " - At least 50% valid clues: 'atleast_50_valid_clues.csv'\n",
      " - Invalid rounds: 'invalid_rounds_due_to_dictionary.csv'\n"
     ]
    }
   ],
   "source": [
    "# Load dictionaries for each language\n",
    "def load_dictionary(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        return set(word.strip().lower() for word in file.readlines())\n",
    "\n",
    "# Load the dictionaries (adjust the file paths as necessary)\n",
    "english_words = load_dictionary('words.txt')\n",
    "german_words = load_dictionary('vocab_german.txt')\n",
    "french_words = load_dictionary('francais.txt')\n",
    "\n",
    "# Function to check if clues exist in the respective language's dictionary\n",
    "def check_clues_against_dictionary(dataframe, clues_column, language_column):\n",
    "    all_valid_rows = []\n",
    "    atleast_75_valid_rows = []\n",
    "    atleast_50_valid_rows = []\n",
    "    invalid_rows = []\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        clues_list = str(row[clues_column]).split(',')\n",
    "        language = row[language_column].strip().lower()\n",
    "\n",
    "        # Select the correct dictionary based on the language of the round\n",
    "        if language == 'english':\n",
    "            dictionary = english_words\n",
    "        elif language == 'deutsch':\n",
    "            dictionary = german_words\n",
    "        elif language == 'français':\n",
    "            dictionary = french_words \n",
    "        else:\n",
    "            continue  # Skip if the language is not recognized\n",
    "        \n",
    "        valid_clues = [clue.strip().lower() for clue in clues_list if clue.strip().lower() in dictionary]\n",
    "        total_clues = len(clues_list)\n",
    "        valid_clues_count = len(valid_clues)\n",
    "\n",
    "        # Categorize the row based on the percentage of valid clues\n",
    "        if valid_clues_count == total_clues:\n",
    "            all_valid_rows.append(index)\n",
    "            atleast_75_valid_rows.append(index)\n",
    "            atleast_50_valid_rows.append(index)\n",
    "        elif valid_clues_count >= 0.75 * total_clues:\n",
    "            atleast_75_valid_rows.append(index)\n",
    "            atleast_50_valid_rows.append(index)\n",
    "        elif valid_clues_count >= 0.50 * total_clues:\n",
    "            atleast_50_valid_rows.append(index)\n",
    "        else:\n",
    "            invalid_rows.append(index)\n",
    "\n",
    "    # Create DataFrames based on the indices\n",
    "    df_all_valid = dataframe.loc[all_valid_rows]\n",
    "    df_atleast_75_valid = dataframe.loc[atleast_75_valid_rows]\n",
    "    df_atleast_50_valid = dataframe.loc[atleast_50_valid_rows]\n",
    "    df_invalid = dataframe.loc[invalid_rows]\n",
    "\n",
    "    return df_all_valid, df_atleast_75_valid, df_atleast_50_valid, df_invalid\n",
    "\n",
    "# Assuming df_cleaned is your DataFrame after the previous cleaning steps\n",
    "df_all_valid, df_atleast_75_valid, df_atleast_50_valid, df_invalid = check_clues_against_dictionary(df_cleaned_with_cleaned_clues, 'Clues', 'Language')\n",
    "\n",
    "# Save the DataFrames to CSV files\n",
    "df_all_valid.to_csv('fully_valid_clues.csv', index=False)\n",
    "df_atleast_75_valid.to_csv('atleast_75_valid_clues.csv', index=False)\n",
    "df_atleast_50_valid.to_csv('atleast_50_valid_clues.csv', index=False)\n",
    "df_invalid.to_csv('invalid_rounds_due_to_dictionary.csv', index=False)\n",
    "\n",
    "# Print out the counts of rounds in each category\n",
    "print(\"Summary of Rounds Based on Dictionary Validation:\")\n",
    "print(f\" - Rounds where every clue is valid: {len(df_all_valid)}\")\n",
    "print(f\" - Rounds where at least 75% of clues are valid: {len(df_atleast_75_valid)}\")\n",
    "print(f\" - Rounds where at least 50% of clues are valid: {len(df_atleast_50_valid)}\")\n",
    "print(f\" - Rounds rejected due to invalid clues: {len(df_invalid)}\")\n",
    "print(f\"Total number of rows in the dataset: {len(df_cleaned_with_cleaned_clues)}\")\n",
    "\n",
    "print(\"\\nFiles have been saved:\")\n",
    "print(\" - Fully valid clues: 'fully_valid_clues.csv'\")\n",
    "print(\" - At least 75% valid clues: 'atleast_75_valid_clues.csv'\")\n",
    "print(\" - At least 50% valid clues: 'atleast_50_valid_clues.csv'\")\n",
    "print(\" - Invalid rounds: 'invalid_rounds_due_to_dictionary.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
